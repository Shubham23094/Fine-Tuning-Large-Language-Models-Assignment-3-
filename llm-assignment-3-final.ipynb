{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:52:42.285989Z","iopub.status.busy":"2024-11-04T16:52:42.285076Z","iopub.status.idle":"2024-11-04T16:53:23.472584Z","shell.execute_reply":"2024-11-04T16:53:23.471447Z","shell.execute_reply.started":"2024-11-04T16:52:42.285936Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.18.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.9.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.4.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.1.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.67.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.24.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (23.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (5.28.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (68.2.2)\n","Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.1)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.1)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n","Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.12.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.6)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.4.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.14.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"]}],"source":["# Install PyTorch\n","!pip install torch tensorboard\n","\n","# Install Hugging Face libraries\n","!pip install transformers datasets accelerate evaluate bitsandbytes huggingface_hub trl peft matplotlib scikit-learn seaborn"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:53:41.828257Z","iopub.status.busy":"2024-11-04T16:53:41.827676Z","iopub.status.idle":"2024-11-04T16:53:42.464227Z","shell.execute_reply":"2024-11-04T16:53:42.463255Z","shell.execute_reply.started":"2024-11-04T16:53:41.828222Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import functools\n","import csv\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","import evaluate\n","from datasets import Dataset, load_dataset\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n","\n","from datasets import Dataset, DatasetDict\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    pipeline,\n",")\n","from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n","from trl import SFTTrainer"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:53:42.466043Z","iopub.status.busy":"2024-11-04T16:53:42.465433Z","iopub.status.idle":"2024-11-04T16:53:47.594120Z","shell.execute_reply":"2024-11-04T16:53:47.593377Z","shell.execute_reply.started":"2024-11-04T16:53:42.466008Z"},"trusted":true},"outputs":[],"source":["# Load the SNLI dataset from Hugging Face\n","snli = load_dataset('snli')\n","\n","# Function to select samples as described\n","def select_samples(dataset, total_samples, step):\n","    indices = list(range(0, total_samples, step))\n","    return dataset.select(indices)\n","\n","# Select samples for training, validation, and test\n","train_data = select_samples(snli['train'], 550000, 550)\n","validation_data = select_samples(snli['validation'], 10000, 100)\n","test_data = select_samples(snli['test'], 10000, 100)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:53:47.595488Z","iopub.status.busy":"2024-11-04T16:53:47.595188Z","iopub.status.idle":"2024-11-04T16:53:48.088866Z","shell.execute_reply":"2024-11-04T16:53:48.087952Z","shell.execute_reply.started":"2024-11-04T16:53:47.595455Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_1800/218134254.py:14: FutureWarning: \n","\n","Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n","\n","  sns.barplot(x=labels, y=counts, palette=\"viridis\")\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from collections import Counter\n","\n","# Count occurrences of each label in the dataset\n","label_counts = Counter(test_data[\"label\"])  # Replace with the appropriate column for labels if different\n","\n","# Extract labels and counts\n","labels = list(label_counts.keys())\n","counts = list(label_counts.values())\n","\n","# Plotting the distribution\n","plt.figure(figsize=(8, 6))\n","sns.barplot(x=labels, y=counts, palette=\"viridis\")\n","plt.xlabel(\"Classes\")\n","plt.ylabel(\"Count\")\n","plt.title(\"Class Distribution in Test Data\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:53:48.091884Z","iopub.status.busy":"2024-11-04T16:53:48.090740Z","iopub.status.idle":"2024-11-04T16:53:48.099269Z","shell.execute_reply":"2024-11-04T16:53:48.098339Z","shell.execute_reply.started":"2024-11-04T16:53:48.091839Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'premise': 'A person on a horse jumps over a broken down airplane.',\n"," 'hypothesis': 'A person is training his horse for a competition.',\n"," 'label': 1}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:53:48.101003Z","iopub.status.busy":"2024-11-04T16:53:48.100557Z","iopub.status.idle":"2024-11-04T16:53:48.109392Z","shell.execute_reply":"2024-11-04T16:53:48.108570Z","shell.execute_reply.started":"2024-11-04T16:53:48.100961Z"},"trusted":true},"outputs":[],"source":["mapping = {'entailment': 0, 'neutral': 1, 'contradiction': 2}"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:54:42.679849Z","iopub.status.busy":"2024-11-04T16:54:42.679164Z","iopub.status.idle":"2024-11-04T16:55:06.668320Z","shell.execute_reply":"2024-11-04T16:55:06.667376Z","shell.execute_reply.started":"2024-11-04T16:54:42.679808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample Training Data: {'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"A person on a horse jumps over a broken down airplane.\"\\nHypothesis: \"A person is training his horse for a competition.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.', 'targets': '1'}\n","Sample Validation Data: {'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"Two women are embracing while holding to go packages.\"\\nHypothesis: \"The sisters are hugging goodbye while holding to go packages after just eating lunch.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.', 'targets': '1'}\n","Sample Testing Data: {'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"This church choir sings to the masses as they sing joyous songs from the book at a church.\"\\nHypothesis: \"The church has cracks in the ceiling.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.', 'targets': '1'}\n"]}],"source":["# from datasets import Dataset\n","\n","# # Define the prompt generation function\n","# def formatting_func(example):\n","#     prompt = (\n","#         f\"Task: Recognize Textual Entailment\\n\"\n","#         f\"Premise: \\\"{example['premise']}\\\"\\n\"\n","#         f\"Hypothesis: \\\"{example['hypothesis']}\\\"\\n\"\n","#         f\"Question: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\n\"\n","#         f\"Options:\\n\"\n","#         f\"0: entailment\\n\"\n","#         f\"1: neutral\\n\"\n","#         f\"2: contradiction\\n\"\n","#         f\"Please select the correct option number.\"\n","#     )\n","#     return prompt\n","\n","# # Preprocessing function to format the data\n","# def preprocess_function(dataframe):\n","#     inputs = []\n","#     targets = []\n","#     for i in range(dataframe.shape[0]):\n","#         # Use the formatting function to generate the prompt\n","#         input_text = formatting_func({\n","#             'premise': dataframe['premise'][i],\n","#             'hypothesis': dataframe['hypothesis'][i]\n","#         })\n","        \n","#         # Target text is the label mapped to string format\n","#         target_text = str(dataframe['label'][i])\n","        \n","#         # Append to the lists\n","#         inputs.append(input_text)\n","#         targets.append(target_text)\n","    \n","#     # Return as a dictionary suitable for Dataset creation\n","#     return {\"inputs\": inputs, \"targets\": targets}\n","\n","# # Apply preprocessing and convert to Dataset\n","# train_data_p = Dataset.from_dict(preprocess_function(train_data))       # For training\n","# eval_data_p = Dataset.from_dict(preprocess_function(validation_data))   # For validation\n","# test_data_p = Dataset.from_dict(preprocess_function(test_data))         # For testing\n","\n","# # Optionally, print a sample to verify\n","# print(\"Sample Training Data:\", train_data_p[0])\n","# print(\"Sample Validation Data:\", eval_data_p[0])\n","# print(\"Sample Testing Data:\", test_data_p[0])\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample Training Data: {'text': 'Task: Recognize Textual Entailment\\nPremise: \"A person on a horse jumps over a broken down airplane.\"\\nHypothesis: \"A person is training his horse for a competition.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.\\nAnswer: 1'}\n","Sample Validation Data: {'text': 'Task: Recognize Textual Entailment\\nPremise: \"Two women are embracing while holding to go packages.\"\\nHypothesis: \"The sisters are hugging goodbye while holding to go packages after just eating lunch.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.\\nAnswer: 1'}\n","Sample Testing Data: {'text': 'Task: Recognize Textual Entailment\\nPremise: \"This church choir sings to the masses as they sing joyous songs from the book at a church.\"\\nHypothesis: \"The church has cracks in the ceiling.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.\\nAnswer: 1'}\n"]}],"source":["from datasets import Dataset\n","\n","# Define the prompt generation function\n","def formatting_func(example):\n","    prompt = (\n","        f\"Task: Recognize Textual Entailment\\n\"\n","        f\"Premise: \\\"{example['premise']}\\\"\\n\"\n","        f\"Hypothesis: \\\"{example['hypothesis']}\\\"\\n\"\n","        f\"Question: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\n\"\n","        f\"Options:\\n\"\n","        f\"0: entailment\\n\"\n","        f\"1: neutral\\n\"\n","        f\"2: contradiction\\n\"\n","        f\"Please select the correct option number.\"\n","    )\n","    return prompt\n","\n","# Preprocessing function to format the data into a single prompt with target included\n","def preprocess_function(dataframe):\n","    prompts = []\n","    for i in range(dataframe.shape[0]):\n","        # Use the formatting function to generate the prompt\n","        input_text = formatting_func({\n","            'premise': dataframe['premise'][i],\n","            'hypothesis': dataframe['hypothesis'][i]\n","        })\n","        \n","        # Append the target label to the prompt as the answer\n","        target_text = str(dataframe['label'][i])\n","        prompt_with_answer = f\"{input_text}\\nAnswer: {target_text}\"\n","        \n","        # Append to the list\n","        prompts.append(prompt_with_answer)\n","    \n","    # Return as a dictionary suitable for Dataset creation\n","    return {\"text\": prompts}\n","\n","# Apply preprocessing and convert to Dataset\n","train_data_p = Dataset.from_dict(preprocess_function(train_data))       # For training\n","eval_data_p = Dataset.from_dict(preprocess_function(validation_data))   # For validation\n","test_data_p = Dataset.from_dict(preprocess_function(test_data))         # For testing\n","\n","# Optionally, print a sample to verify\n","print(\"Sample Training Data:\", train_data_p[0])\n","print(\"Sample Validation Data:\", eval_data_p[0])\n","print(\"Sample Testing Data:\", test_data_p[0])\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:55:06.670973Z","iopub.status.busy":"2024-11-04T16:55:06.670160Z","iopub.status.idle":"2024-11-04T16:55:06.677289Z","shell.execute_reply":"2024-11-04T16:55:06.676331Z","shell.execute_reply.started":"2024-11-04T16:55:06.670905Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"This church choir sings to the masses as they sing joyous songs from the book at a church.\"\\nHypothesis: \"The church has cracks in the ceiling.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.',\n"," 'targets': '1'}"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["test_data_p[0]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T16:56:15.350976Z","iopub.status.busy":"2024-11-04T16:56:15.350274Z","iopub.status.idle":"2024-11-04T16:58:32.016847Z","shell.execute_reply":"2024-11-04T16:58:32.015894Z","shell.execute_reply.started":"2024-11-04T16:56:15.350934Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0827bfce5fa44b6b9335867e292d66ab","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["model_name = \"microsoft/phi-2\"\n","compute_dtype = torch.float16\n","\n","# Quantization config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["import warnings\n","\n","# Suppress specific warning message\n","warnings.filterwarnings(\"ignore\", message=\"Setting `pad_token_id` to `eos_token_id`: None for open-end generation.\")\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:11:10.549845Z","iopub.status.busy":"2024-11-04T17:11:10.549087Z","iopub.status.idle":"2024-11-04T17:16:02.817631Z","shell.execute_reply":"2024-11-04T17:16:02.816685Z","shell.execute_reply.started":"2024-11-04T17:11:10.549801Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing test samples:   0%|          | 0/100 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   1%|          | 1/100 [00:02<04:32,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   2%|▏         | 2/100 [00:06<05:00,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   3%|▎         | 3/100 [00:09<05:03,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   4%|▍         | 4/100 [00:11<04:10,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   5%|▌         | 5/100 [00:14<04:25,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   6%|▌         | 6/100 [00:17<04:43,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   7%|▋         | 7/100 [00:20<04:32,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   8%|▊         | 8/100 [00:23<04:25,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:   9%|▉         | 9/100 [00:26<04:39,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  10%|█         | 10/100 [00:29<04:34,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  11%|█         | 11/100 [00:32<04:30,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  12%|█▏        | 12/100 [00:36<04:39,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  13%|█▎        | 13/100 [00:37<03:55,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  14%|█▍        | 14/100 [00:40<03:48,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  15%|█▌        | 15/100 [00:43<04:01,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  16%|█▌        | 16/100 [00:47<04:17,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  17%|█▋        | 17/100 [00:49<04:07,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  18%|█▊        | 18/100 [00:52<03:58,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  19%|█▉        | 19/100 [00:55<03:56,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  20%|██        | 20/100 [00:58<03:46,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  21%|██        | 21/100 [01:01<03:51,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  22%|██▏       | 22/100 [01:03<03:38,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  23%|██▎       | 23/100 [01:07<03:41,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  24%|██▍       | 24/100 [01:10<03:44,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  25%|██▌       | 25/100 [01:13<03:43,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  26%|██▌       | 26/100 [01:15<03:18,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  27%|██▋       | 27/100 [01:18<03:28,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  28%|██▊       | 28/100 [01:21<03:25,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  29%|██▉       | 29/100 [01:23<03:09,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  30%|███       | 30/100 [01:26<03:21,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  31%|███       | 31/100 [01:30<03:24,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  32%|███▏      | 32/100 [01:31<02:56,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  33%|███▎      | 33/100 [01:34<03:01,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  34%|███▍      | 34/100 [01:38<03:09,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  35%|███▌      | 35/100 [01:41<03:18,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  36%|███▌      | 36/100 [01:44<03:14,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  37%|███▋      | 37/100 [01:47<03:15,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  38%|███▊      | 38/100 [01:50<03:14,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  39%|███▉      | 39/100 [01:54<03:09,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  40%|████      | 40/100 [01:55<02:44,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  41%|████      | 41/100 [01:59<02:48,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  42%|████▏     | 42/100 [02:02<02:49,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  43%|████▎     | 43/100 [02:05<02:46,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  44%|████▍     | 44/100 [02:07<02:41,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  45%|████▌     | 45/100 [02:10<02:38,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  46%|████▌     | 46/100 [02:13<02:28,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  47%|████▋     | 47/100 [02:16<02:30,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  48%|████▊     | 48/100 [02:19<02:30,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  49%|████▉     | 49/100 [02:22<02:28,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  50%|█████     | 50/100 [02:25<02:28,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  51%|█████     | 51/100 [02:28<02:28,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  52%|█████▏    | 52/100 [02:31<02:32,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  53%|█████▎    | 53/100 [02:34<02:18,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  54%|█████▍    | 54/100 [02:37<02:17,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  55%|█████▌    | 55/100 [02:40<02:15,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  56%|█████▌    | 56/100 [02:43<02:14,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  57%|█████▋    | 57/100 [02:46<02:08,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  58%|█████▊    | 58/100 [02:49<02:08,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  59%|█████▉    | 59/100 [02:51<01:53,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  60%|██████    | 60/100 [02:54<01:52,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  61%|██████    | 61/100 [02:57<01:52,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  62%|██████▏   | 62/100 [03:00<01:44,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  63%|██████▎   | 63/100 [03:02<01:34,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  64%|██████▍   | 64/100 [03:05<01:38,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  65%|██████▌   | 65/100 [03:08<01:40,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  66%|██████▌   | 66/100 [03:11<01:40,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  67%|██████▋   | 67/100 [03:14<01:35,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  68%|██████▊   | 68/100 [03:18<01:38,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  69%|██████▉   | 69/100 [03:21<01:36,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  70%|███████   | 70/100 [03:23<01:25,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  71%|███████   | 71/100 [03:26<01:27,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  72%|███████▏  | 72/100 [03:29<01:23,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  73%|███████▎  | 73/100 [03:33<01:23,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  74%|███████▍  | 74/100 [03:35<01:19,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  75%|███████▌  | 75/100 [03:39<01:15,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  76%|███████▌  | 76/100 [03:42<01:13,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  77%|███████▋  | 77/100 [03:45<01:10,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  78%|███████▊  | 78/100 [03:48<01:08,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  79%|███████▉  | 79/100 [03:51<01:04,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  80%|████████  | 80/100 [03:53<00:58,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  81%|████████  | 81/100 [03:56<00:52,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  82%|████████▏ | 82/100 [03:58<00:47,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  83%|████████▎ | 83/100 [04:01<00:47,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  84%|████████▍ | 84/100 [04:03<00:41,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  85%|████████▌ | 85/100 [04:07<00:42,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  86%|████████▌ | 86/100 [04:10<00:41,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  87%|████████▋ | 87/100 [04:13<00:39,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  88%|████████▊ | 88/100 [04:17<00:37,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  89%|████████▉ | 89/100 [04:19<00:30,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  90%|█████████ | 90/100 [04:22<00:29,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  91%|█████████ | 91/100 [04:24<00:25,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  92%|█████████▏| 92/100 [04:28<00:23,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  93%|█████████▎| 93/100 [04:31<00:20,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  94%|█████████▍| 94/100 [04:34<00:17,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  95%|█████████▌| 95/100 [04:37<00:15,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  96%|█████████▌| 96/100 [04:40<00:12,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  97%|█████████▋| 97/100 [04:44<00:09,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  98%|█████████▊| 98/100 [04:47<00:06,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples:  99%|█████████▉| 99/100 [04:50<00:03,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n","Processing test samples: 100%|██████████| 100/100 [04:52<00:00,  2.92s/it]"]},{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n","[[26  0  0]\n"," [33  0  0]\n"," [30  0  5]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.29      1.00      0.45        26\n","           1       0.00      0.00      0.00        33\n","           2       1.00      0.14      0.25        35\n","\n","    accuracy                           0.33        94\n","   macro avg       0.43      0.38      0.23        94\n","weighted avg       0.45      0.33      0.22        94\n","\n","Balanced Accuracy Score: 0.38095238095238093\n","Accuracy Score: 0.32978723404255317\n"]},{"name":"stderr","output_type":"stream","text":["\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n","from tqdm import tqdm\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n","\n","# Ensure both pad_token_id and eos_token_id are set in tokenizer and model\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Explicitly set these in the model configuration to avoid warnings\n","model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.eos_token_id = tokenizer.eos_token_id\n","\n","\n","# Define the performance metrics function\n","def get_performance_metrics(actual, predicted):\n","    actual = list(map(str, actual))\n","    predicted = list(map(str, predicted))\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(actual, predicted))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(actual, predicted))\n","    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(actual, predicted))\n","    print(\"Accuracy Score:\", accuracy_score(actual, predicted))\n","\n","# Function to generate predictions with error handling\n","def generate_prediction(model, tokenizer, premise, hypothesis):\n","    try:\n","        prompt = (\n","            f\"Task: Recognize Textual Entailment\\n\"\n","            f\"Premise: \\\"{premise}\\\"\\n\"\n","            f\"Hypothesis: \\\"{hypothesis}\\\"\\n\"\n","            f\"Question: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\n\"\n","            f\"Options:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.\\nAnswer:\"\n","        )\n","        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n","        output = model.generate(**inputs, max_length=150)\n","        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","        \n","        # Extract answer from model output and ensure it's one of \"0\", \"1\", or \"2\"\n","        answer = generated_text.split(\"Answer:\")[-1].strip().split()[0]  # Get the first word after \"Answer:\"\n","        if answer in {\"0:\", \"0\"}:\n","            return \"0\"\n","        elif answer in {\"1:\", \"1\"}:\n","            return \"1\"\n","        elif answer in {\"2:\", \"2\"}:\n","            return \"2\"\n","        else:\n","            return \"unknown\"  # Fallback for unexpected output\n","    except Exception as e:\n","        print(f\"Error in prediction: {e}\")\n","        return \"unknown\"\n","\n","# Run evaluation on the test data with tqdm for progress\n","actual_labels = []\n","predicted_labels = []\n","\n","for sample in tqdm(test_data_p, desc=\"Processing test samples\"):\n","    premise = sample['inputs'].split('Premise: \"')[-1].split('\"')[0]\n","    hypothesis = sample['inputs'].split('Hypothesis: \"')[-1].split('\"')[0]\n","    actual = sample['targets']\n","    \n","    # Generate prediction\n","    predicted = generate_prediction(model, tokenizer, premise, hypothesis)\n","    \n","    # Only consider valid predictions\n","    if predicted in {\"0\", \"1\", \"2\"}:\n","        actual_labels.append(actual)\n","        predicted_labels.append(predicted)\n","\n","# Evaluate model performance only on valid predictions\n","get_performance_metrics(actual_labels, predicted_labels)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:16:14.084249Z","iopub.status.busy":"2024-11-04T17:16:14.083857Z","iopub.status.idle":"2024-11-04T17:16:14.422199Z","shell.execute_reply":"2024-11-04T17:16:14.421268Z","shell.execute_reply.started":"2024-11-04T17:16:14.084212Z"},"trusted":true},"outputs":[],"source":["from peft import LoraConfig, get_peft_model\n","\n","config = LoraConfig(\n","    r=32,\n","    lora_alpha=64,\n","    target_modules=[\n","        \"q_proj\",\n","        \"k_proj\",\n","        \"v_proj\",\n","        \"o_proj\",\n","        \"gate_proj\",\n","        \"up_proj\",\n","        \"down_proj\",\n","        \"lm_head\",\n","    ],\n","    bias=\"none\",\n","    lora_dropout=0.05,  # Conventional\n","    task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def print_trainable_parameters(model):\n","    \"\"\"\n","    Prints the number of trainable parameters in the model.\n","    \"\"\"\n","    trainable_params = 0\n","    all_param = 0\n","    for _, param in model.named_parameters():\n","        all_param += param.numel()\n","        if param.requires_grad:\n","            trainable_params += param.numel()\n","    print(\n","        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n","    )"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 17448960 || all params: 1538841600 || trainable%: 1.1339022807805559\n"]}],"source":["print_trainable_parameters(model)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:16:16.961515Z","iopub.status.busy":"2024-11-04T17:16:16.961121Z","iopub.status.idle":"2024-11-04T17:16:16.996793Z","shell.execute_reply":"2024-11-04T17:16:16.995885Z","shell.execute_reply.started":"2024-11-04T17:16:16.961476Z"},"trusted":true},"outputs":[],"source":["from peft import prepare_model_for_kbit_training\n","\n","model.gradient_checkpointing_enable()\n","model = prepare_model_for_kbit_training(model)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:16:18.036409Z","iopub.status.busy":"2024-11-04T17:16:18.036020Z","iopub.status.idle":"2024-11-04T17:16:18.051885Z","shell.execute_reply":"2024-11-04T17:16:18.050838Z","shell.execute_reply.started":"2024-11-04T17:16:18.036370Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): PhiForCausalLM(\n","      (model): PhiModel(\n","        (embed_tokens): Embedding(51200, 2560)\n","        (embed_dropout): Dropout(p=0.0, inplace=False)\n","        (layers): ModuleList(\n","          (0-31): 32 x PhiDecoderLayer(\n","            (self_attn): PhiAttention(\n","              (q_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear4bit(\n","                (base_layer): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2560, out_features=32, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=32, out_features=2560, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (dense): Linear4bit(in_features=2560, out_features=2560, bias=True)\n","              (rotary_emb): PhiRotaryEmbedding()\n","            )\n","            (mlp): PhiMLP(\n","              (activation_fn): NewGELUActivation()\n","              (fc1): Linear4bit(in_features=2560, out_features=10240, bias=True)\n","              (fc2): Linear4bit(in_features=10240, out_features=2560, bias=True)\n","            )\n","            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","            (resid_dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (final_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n","        (rotary_emb): PhiRotaryEmbedding()\n","      )\n","      (lm_head): lora.Linear(\n","        (base_layer): Linear(in_features=2560, out_features=51200, bias=True)\n","        (lora_dropout): ModuleDict(\n","          (default): Dropout(p=0.05, inplace=False)\n","        )\n","        (lora_A): ModuleDict(\n","          (default): Linear(in_features=2560, out_features=32, bias=False)\n","        )\n","        (lora_B): ModuleDict(\n","          (default): Linear(in_features=32, out_features=51200, bias=False)\n","        )\n","        (lora_embedding_A): ParameterDict()\n","        (lora_embedding_B): ParameterDict()\n","        (lora_magnitude_vector): ModuleDict()\n","      )\n","    )\n","  )\n",")\n"]}],"source":["print(model)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:16:22.679675Z","iopub.status.busy":"2024-11-04T17:16:22.679285Z","iopub.status.idle":"2024-11-04T17:16:22.912402Z","shell.execute_reply":"2024-11-04T17:16:22.911602Z","shell.execute_reply.started":"2024-11-04T17:16:22.679637Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n","\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:16:24.795744Z","iopub.status.busy":"2024-11-04T17:16:24.795381Z","iopub.status.idle":"2024-11-04T17:16:24.800734Z","shell.execute_reply":"2024-11-04T17:16:24.799707Z","shell.execute_reply.started":"2024-11-04T17:16:24.795711Z"},"trusted":true},"outputs":[],"source":["model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"markdown","metadata":{},"source":["# Finetunning phi-2 on stanfordnlp/snli dataset"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from accelerate import Accelerator\n","\n","# Initialize Accelerator\n","accelerator = Accelerator()\n","\n","# Prepare model using accelerator\n","model = accelerator.prepare_model(model)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-11-04T17:20:49.309799Z","iopub.status.busy":"2024-11-04T17:20:49.309158Z","iopub.status.idle":"2024-11-04T17:20:53.196678Z","shell.execute_reply":"2024-11-04T17:20:53.195768Z","shell.execute_reply.started":"2024-11-04T17:20:49.309759Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8f7713d157e4144a6d1315c97eff6fc","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"513f3c4c58e549a8b6cf08980d9f4394","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Sample Tokenized Training Data: {'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"A person on a horse jumps over a broken down airplane.\"\\nHypothesis: \"A person is training his horse for a competition.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.', 'targets': '1', 'input_ids': tensor([15941,    25, 31517,  ..., 50256, 50256, 50256]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'labels': tensor([  352, 50256, 50256,  ..., 50256, 50256, 50256])}\n","Sample Tokenized Validation Data: {'inputs': 'Task: Recognize Textual Entailment\\nPremise: \"Two women are embracing while holding to go packages.\"\\nHypothesis: \"The sisters are hugging goodbye while holding to go packages after just eating lunch.\"\\nQuestion: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\nOptions:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.', 'targets': '1', 'input_ids': tensor([15941,    25, 31517,  ..., 50256, 50256, 50256]), 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]), 'labels': tensor([  352, 50256, 50256,  ..., 50256, 50256, 50256])}\n"]}],"source":["# Define the tokenization function\n","def tokenize_function(example):\n","    # Tokenize the inputs and targets separately\n","    inputs = tokenizer(\n","        example[\"inputs\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=None,  # Set max length based on model requirements\n","        return_tensors=\"pt\"\n","    )\n","    targets = tokenizer(\n","        example[\"targets\"],\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=None,  # Set max length for target based on label size\n","        return_tensors=\"pt\"\n","    )\n","    \n","    # Renaming labels for the format needed in transformers\n","    labels = targets[\"input_ids\"]\n","    \n","    # Return as dictionary including inputs and labels for the model\n","    return {\n","        \"input_ids\": inputs[\"input_ids\"].squeeze(),\n","        \"attention_mask\": inputs[\"attention_mask\"].squeeze(),\n","        \"labels\": labels.squeeze()\n","    }\n","\n","# Apply tokenization on train, validation, and test data\n","train_data_tokenized = train_data_p.map(tokenize_function, batched=True)\n","eval_data_tokenized = eval_data_p.map(tokenize_function, batched=True)\n","\n","# Optionally, set the format for PyTorch tensors\n","train_data_tokenized.set_format(type=\"torch\")\n","eval_data_tokenized.set_format(type=\"torch\")\n","\n","# Check sample from tokenized data\n","print(\"Sample Tokenized Training Data:\", train_data_tokenized[0])\n","print(\"Sample Tokenized Validation Data:\", eval_data_tokenized[0])\n"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["# Set training arguments\n","training_arguments = TrainingArguments(\n","    output_dir = \"/root/model\",\n","    num_train_epochs = 5,\n","    fp16 = False,\n","    bf16 = False,\n","    per_device_train_batch_size = 64,\n","    per_device_eval_batch_size = 4,\n","    gradient_accumulation_steps = 1,\n","    gradient_checkpointing = True,\n","    max_grad_norm = 0.3,\n","    learning_rate = 2e-4,\n","    weight_decay = 0.001,\n","    optim = \"paged_adamw_32bit\",\n","    lr_scheduler_type = \"cosine\",\n","    max_steps = -1,\n","    warmup_ratio = 0.03,\n","    group_by_length = True,\n","    save_steps = 16,\n","    logging_steps = 16,\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '0.13.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:309: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:328: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f7e7821d731843b195b3407c8be064d5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e71bd085f4a24433b4665a451eb74007","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [80/80 09:40, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>16</td>\n","      <td>2.429600</td>\n","    </tr>\n","    <tr>\n","      <td>32</td>\n","      <td>2.427700</td>\n","    </tr>\n","    <tr>\n","      <td>48</td>\n","      <td>2.427000</td>\n","    </tr>\n","    <tr>\n","      <td>64</td>\n","      <td>2.429200</td>\n","    </tr>\n","    <tr>\n","      <td>80</td>\n","      <td>2.427600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"]},{"data":{"text/plain":["TrainOutput(global_step=80, training_loss=2.4282390117645263, metrics={'train_runtime': 590.1212, 'train_samples_per_second': 8.473, 'train_steps_per_second': 0.136, 'total_flos': 8418950779699200.0, 'train_loss': 2.4282390117645263, 'epoch': 5.0})"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["# Set supervised fine-tuning parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=train_data_p,\n","    eval_dataset=eval_data_p,\n","    dataset_text_field=\"text\",\n","    max_seq_length= None,\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n",")\n","\n","# Train model\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["#Inference on finetunemodel"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import os\n","import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","from sklearn.metrics import confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n","from tqdm import tqdm\n","\n","# Model directory and specific checkpoint\n","checkpoint_path = \"/root/model/checkpoint-80\"\n","\n","# Load the tokenizer from the specific checkpoint\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint_path, add_prefix_space=True)\n","\n","# Ensure pad_token_id and eos_token_id are set\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# Define performance metrics function\n","def get_performance_metrics(actual, predicted):\n","    actual = list(map(str, actual))\n","    predicted = list(map(str, predicted))\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix(actual, predicted))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(actual, predicted))\n","    print(\"Balanced Accuracy Score:\", balanced_accuracy_score(actual, predicted))\n","    print(\"Accuracy Score:\", accuracy_score(actual, predicted))\n","\n","# Prediction generation function\n","def generate_prediction(model, tokenizer, premise, hypothesis):\n","    try:\n","        prompt = (\n","            f\"Task: Recognize Textual Entailment\\n\"\n","            f\"Premise: \\\"{premise}\\\"\\n\"\n","            f\"Hypothesis: \\\"{hypothesis}\\\"\\n\"\n","            f\"Question: Based on the premise, does the hypothesis entail, contradict, or is it neutral with respect to the premise?\\n\"\n","            f\"Options:\\n0: entailment\\n1: neutral\\n2: contradiction\\nPlease select the correct option number.\\nAnswer:\"\n","        )\n","        inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True).to(model.device)\n","        output = model.generate(**inputs, max_length=150)\n","        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","        \n","        # Extract answer from model output\n","        answer = generated_text.split(\"Answer:\")[-1].strip().split()[0]\n","        if answer in {\"0:\", \"0\"}:\n","            return \"0\"\n","        elif answer in {\"1:\", \"1\"}:\n","            return \"1\"\n","        elif answer in {\"2:\", \"2\"}:\n","            return \"2\"\n","        else:\n","            return \"unknown\"  # Fallback for unexpected output\n","    except Exception as e:\n","        print(f\"Error in prediction: {e}\")\n","        return \"unknown\"\n","\n","# Load the model from the specific checkpoint\n","print(f\"\\nEvaluating checkpoint: {checkpoint_path}\")\n","model = AutoModelForCausalLM.from_pretrained(checkpoint_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.config.pad_token_id = tokenizer.pad_token_id\n","model.config.eos_token_id = tokenizer.eos_token_id\n","model.eval()\n","\n","# Run evaluation on the test data\n","actual_labels = []\n","predicted_labels = []\n","\n","for sample in tqdm(test_data_p, desc=f\"Processing test samples for {checkpoint_path}\"):\n","    premise = sample['inputs'].split('Premise: \"')[-1].split('\"')[0]\n","    hypothesis = sample['inputs'].split('Hypothesis: \"')[-1].split('\"')[0]\n","    actual = sample['targets']\n","    \n","    # Generate prediction\n","    predicted = generate_prediction(model, tokenizer, premise, hypothesis)\n","    \n","    # Only consider valid predictions\n","    if predicted in {\"0\", \"1\", \"2\"}:\n","        actual_labels.append(actual)\n","        predicted_labels.append(predicted)\n","\n","# Evaluate model performance for this checkpoint\n","print(f\"\\nPerformance metrics for checkpoint: {checkpoint_path}\")\n","get_performance_metrics(actual_labels, predicted_labels)\n","\n","# Clear model from memory\n","del model\n","torch.cuda.empty_cache()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
